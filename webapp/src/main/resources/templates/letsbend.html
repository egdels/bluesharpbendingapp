<!--
/*
 * Copyright (c) 2023 Christian Kierdorf
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the “Software”),
 * to deal in the Software without restriction, including without limitation
 * the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
 * sell copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
 * OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
 * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
 * WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
 * OTHER DEALINGS IN THE SOFTWARE.
 *
 */
-->
<!DOCTYPE html>
<html th:lang="#{language}" th:xmllang="#{language}" xmlns="http://www.w3.org/1999/xhtml"
      xmlns:th="http://www.thymeleaf.org">
<head th:replace="~{fragments/general :: head}">
    <!-- This content will be replaced by the fragment, but we include it here for clarity -->
    <!-- Polyfills for older browsers will be added in the fragment -->
</head>
<body>
<header th:replace="~{fragments/general :: header}"></header>

<main>
    <div class="container">
        <h2>Let's Bend</h2>
        <div class="select-container">
            <div class="select-group">
                <label for="supportedKeys">Key:</label>
                <select class="form-control" id="supportedKeys" onchange="handleSelectionChange()"
                        th:name="supportedKeys">
                    <option disabled selected th:if="${harmonica == null}" value="">Bitte wählen...</option>
                    <option th:each="key : ${supportedKeys}"
                            th:selected="${key == harmonica.getSelectedKey()}"
                            th:text="${key}"
                            th:value="${key}">
                    </option>
                </select>
            </div>
            <div class="select-group">
                <label for="supportedTunes">Tune:</label>
                <select class="form-control" id="supportedTunes" onchange="handleSelectionChange()"
                        th:name="supportedTunes">
                    <option disabled selected th:if="${harmonica == null}" value="">Bitte wählen...</option>
                    <option th:each="tune : ${supportedTunes}"
                            th:selected="${tune == harmonica.getSelectedTune()}"
                            th:text="${tune}"
                            th:value="${tune}">
                    </option>
                </select>
            </div>
            <div class="select-group checkbox-group" th:classappend="${expertMode != null and expertMode} ? '' : 'single-select'">
            <label class="invisible">Expert</label> <!-- unsichtbares Label für gleichmäßige Ausrichtung -->
                <div class="form-check checkbox-container">
                    <input class="form-check-input" type="checkbox" id="expertMode" name="expertMode"
                           th:checked="${expertMode}" onchange="handleSelectionChange()">
                    <label class="form-check-label" for="expertMode">
                        Expert
                    </label>
                </div>
            </div>
            <div class="select-group" th:classappend="${expertMode} ? '' : 'expert-mode-hidden'">
                <label for="supportedAlgorithms">Algorithm:</label>
                <select class="form-control" id="supportedAlgorithms" onchange="handleSelectionChange()"
                        th:name="supportedAlgorithms">
                    <option disabled selected th:if="${selectedAlgorithm == null}" value="">Bitte wählen...</option>
                    <option th:each="algorithm : ${supportedAlgorithms}"
                            th:selected="${algorithm == selectedAlgorithm}"
                            th:text="${algorithm}"
                            th:value="${algorithm}">
                    </option>
                </select>
            </div>
            <div class="select-group" th:classappend="${expertMode} ? '' : 'expert-mode-hidden'">
                <label for="supportedConcertPitches">Concert Pitch:</label>
                <select class="form-control" id="supportedConcertPitches" onchange="handleSelectionChange()"
                        th:name="supportedConcertPitches">
                    <option disabled selected th:if="${selectedConcertPitch == null}" value="">Bitte wählen...</option>
                    <option th:each="concertPitch : ${supportedConcertPitches}"
                            th:selected="${concertPitch == selectedConcertPitch}"
                            th:text="${concertPitch}"
                            th:value="${concertPitch}">
                    </option>
                </select>
            </div>
            <div class="select-group" th:classappend="${expertMode} ? '' : 'expert-mode-hidden'">
                <label for="supportedConfidences">Confidence:</label>
                <select class="form-control" id="supportedConfidences" onchange="handleSelectionChange()"
                        th:name="supportedConfidences">
                    <option disabled selected th:if="${selectedConfidence == null}" value="">Bitte wählen...</option>
                    <option th:each="confidence : ${supportedConfidences}"
                            th:selected="${confidence == selectedConfidence}"
                            th:text="${confidence}"
                            th:value="${confidence}">
                    </option>
                </select>
            </div>
            <div class="select-group button-group single-select">
                <div class="form-check button-container">
                    <button id="start">Start</button>
                    <button disabled id="stop">Stop</button>
                </div>
            </div>
            <!-- Hidden fields for harmonica frequency range -->
            <input type="hidden" id="harmonicaMinFrequency" th:value="${harmonica.getHarmonicaMinFrequency()}">
            <input type="hidden" id="harmonicaMaxFrequency" th:value="${harmonica.getHarmonicaMaxFrequency()}">
        </div>
        <div id="result" style="margin-top: 20px; padding: 10px; border: 1px solid #ddd;">
            Ergebnis wird hier angezeigt...
        </div>
        <div th:replace="fragments/harmonica-grid :: harmonicaGrid"></div>
    </div>
</main>

<footer th:replace="~{fragments/general :: footer}"></footer>

<script th:inline="javascript" type="module">
    import YINPitchDetector from './scripts/YINPitchDetector.js';
    import MPMPitchDetector from './scripts/MPMPitchDetector.js';
    import HybridPitchDetector from './scripts/HybridPitchDetector.js';
    import NoteLookup from './scripts/NoteLookup.js';
    import NoteUtils from './scripts/NoteUtils.js';

    /**
     * Represents the confidence level as a numerical value.
     * This variable can be used to indicate the degree of certainty or trust
     * in a specific outcome, prediction, or measurement.
     *
     * The value is typically a floating-point number between 0 and 1,
     * where 0 represents no confidence and 1 represents full confidence.
     *
     * In this case, the confidence level is set to 0.7, which indicates
     * a relatively high degree of certainty.
     */
    let confidence = 0.7;
    /**
     * Represents the standard pitch commonly used as a reference for tuning musical instruments.
     *
     * The `concertPitch` variable defines the frequency of the A4 note in Hertz, which serves
     * as the standard tuning frequency. This value is typically set to 440 Hz but can vary,
     * depending on the context or regional preferences in music performance.
     *
     * In this instance, `concertPitch` is set to 442 Hz, which is sometimes used in classical
     * and orchestral music to produce a brighter timbre.
     *
     * This value is used as a reference point for tuning other notes relative to it.
     *
     * Type: Number
     */
    let concertPitch = 442;
    /**
     * A variable that represents the HTML element where results or output will be displayed.
     * It is expected to be associated with a DOM element, typically a div container,
     * that serves as a placeholder for dynamically inserted content.
     */
    let resultDiv;
    /**
     * Represents a MediaStream object which is used to handle audio and video data streams.
     * The MediaStream may contain multiple tracks, such as audio tracks and video tracks.
     * It is commonly used for working with media captured from hardware devices such as cameras and microphones
     * or for handling media in WebRTC applications.
     *
     * Key features:
     * - Provides access to and control of tracks (e.g., audio and video) it contains.
     * - Allows you to add, remove, or manipulate tracks dynamically.
     * - Can be used as a source for various media elements like audio and video players.
     */
    let mediaStream;
    /**
     * Represents an instance of `AudioContext`, which is a part of the Web Audio API.
     * It provides an interface for managing, controlling, and playing audio within web applications.
     * The `audioContext` variable is typically used to create, configure, and connect audio nodes in
     * an audio processing graph, allowing developers to perform operations like audio playback, mixing,
     * and processing.
     *
     * Key features include:
     * - Creating audio sources such as oscillators, buffers, or media streams.
     * - Connecting multiple audio nodes to build an audio graph.
     * - Controlling audio properties such as gain, frequency, and playback rate.
     * - Starting, stopping, and scheduling audio playback.
     * - Supporting spatial audio, effects, and more.
     */
    let audioContext;
    /**
     * Represents a processing node in a system or application workflow.
     *
     * Typically utilized in systems involving pipelines, workflows, or
     * data processing where each node handles specific operations.
     *
     * The processingNode may include logic or metadata relevant to
     * the stage it represents within a larger process.
     *
     * @type {Object}
     */
    let processingNode;

    /**
     * Represents the algorithm name used for processing.
     *
     * The value of this variable is set to 'YIN', which signifies the usage
     * of the YIN algorithm. YIN is typically employed in the context of pitch
     * detection or pitch tracking systems to estimate the fundamental frequency
     * of a signal.
     */
    let algorithm = 'YIN';

    /**
     * Checks if the AudioWorklet API is supported in the current browser environment.
     *
     * @return {boolean} Returns true if the AudioWorklet API is supported, otherwise false.
     */
    function isAudioWorkletSupported() {
        return window.AudioContext && 'audioWorklet' in AudioContext.prototype;
    }

    /**
     * Checks if the browser is Safari.
     *
     * @return {boolean} Returns true if the browser is Safari, otherwise false.
     */
    function isSafari() {
        return !!navigator.vendor && navigator.vendor.indexOf('Apple') > -1 &&
            navigator.userAgent.indexOf('CriOS') === -1 &&
            navigator.userAgent.indexOf('FxiOS') === -1;
    }

    /**
     * Checks if the getUserMedia API is supported in the current browser environment.
     *
     * @return {boolean} Returns true if the getUserMedia API is supported, otherwise false.
     */
    function isGetUserMediaSupported() {
        return !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia);
    }

    /**
     * Checks if the Web Audio API is supported in the current browser environment.
     *
     * @return {boolean} Returns true if the Web Audio API is supported, otherwise false.
     */
    function isWebAudioSupported() {
        return !!(window.AudioContext || window.webkitAudioContext);
    }

    /**
     * Checks if the ScriptProcessorNode API is supported in the current browser environment.
     *
     * @return {boolean} Returns true if the ScriptProcessorNode API is supported, otherwise false.
     */
    function isScriptProcessorSupported() {
        const AudioContext = window.AudioContext || window.webkitAudioContext;
        if (!AudioContext) return false;

        const ctx = new AudioContext();
        const isSupported = typeof ctx.createScriptProcessor === 'function';
        ctx.close();
        return isSupported;
    }


    /**
     * Represents an array of spans.
     * Each span can be an object or a value that defines a segment or section of content or data.
     * This array is designed to store such segments for further processing or display.
     */
    let spans = [];
    document.querySelectorAll('.grid-cell span').forEach(span => {
        if (span.textContent.trim() !== '') {
            spans.push(span);
        }
    });


    /**
     * Handles changes to dynamically update the visual representation of elements within a grid based on data input.
     * It adjusts the position and color of a line element related to a specific grid cell, based on the input's confidence and cents value.
     *
     * @param {Object} data - The input data containing information for updating elements.
     * @param {string} data.noteName - The name of the note to match.
     * @param {number} data.cents - The cents value used to calculate position and color.
     * @param {number} data.confidence - A confidence level used to determine if updates should be applied.
     * @param {number} [precision=0.7] - The minimum confidence threshold required to apply updates.
     *
     * @return {void} This function does not return a value.
     */
    function handleChange(data, precision = 0.7) {
        // Iterate through each span to find the one with text matching data.noteName
        spans.forEach(span => {

            const lineElement = span.parentElement.parentElement.querySelector('.line');
            lineElement.style.visibility = 'hidden';

            if(span.parentElement.parentElement.classList.contains('expanded')) {
                span.parentElement.parentElement.setAttribute('cents-border-text','Cents:'+ "+0".toString().padStart(3, ' '));
            }

            // Check if the text content of the span equals data.noteName
            if (data.confidence >= precision && span.textContent.trim() === data.noteName) {
                // console.log("Matching cell found:", span.parentElement.parentElement);

                // Retrieve the value from data.cents
                const centsValue = Math.round(data.cents);

                const centsString = (centsValue >= 0 ? '+' : '-') + Math.abs(centsValue);
                const formattedCents = centsString.toString().padStart(3, ' ');

                // console.log(formattedCents, formattedCents.length);

                if(span.parentElement.parentElement.classList.contains('expanded')) {
                    span.parentElement.parentElement.setAttribute('cents-border-text', 'Cents:' +  formattedCents);
                }

                // Define the limits for calculation
                const minCents = -50; // Top (upper boundary)
                const maxCents = 50;  // Bottom (lower boundary)

                // Normalize the value from -50 to 50 into a range between 0 and 1
                const normalized = (centsValue - minCents) / (maxCents - minCents);

                // Interpolate color from green (center) to red (top and bottom)
                const red = Math.abs(2 * normalized - 1) * 255; // Red intensity increases away from the center
                const green = (1 - Math.abs(2 * normalized - 1)) * 255; // Green intensity decreases away from the center

                // Create the dynamic color
                const color = `rgb(${Math.round(red)}, ${Math.round(green)}, 0)`;

                // Calculate the dynamic top position in percentage
                const minPercent = 0; // 0% = Top edge
                const maxPercent = 100; // 100% = Bottom edge
                const normalizedTop = normalized * (maxPercent - minPercent) + minPercent;

                const lineHeight = lineElement.offsetHeight;

                // Set the dynamic top position in percentage
                lineElement.style.top = `calc(${normalizedTop}% - ${lineHeight / 2}px)`; // Mitte des Elements berücksichtigen
                lineElement.style.visibility = 'visible';

                // Set the dynamic color of the line
                lineElement.style.backgroundColor = color;

                // console.log(`Cents: ${centsValue}, Normalized: ${normalized}, Color: ${color}`);
            }

        });
    }

    document.addEventListener('DOMContentLoaded', () => {
        const container = document.querySelector('.grid-container');
        let currentCopy = null; // Tracks the current copy (if one exists)

        container.addEventListener('click', (event) => {
            // Check if an element with the class "grid-cell" was clicked (or a child element within a cell)
            const cell = event.target.closest('.grid-cell');

            if (!cell || !container.contains(cell)) return; // If no "grid-cell" is found or the cell is not within the container, exit

            if (cell.classList.contains('channel')) return; // Ignore clicks on elements with the "channel" class

            // Check if the cell is a copy (by checking a CSS class)
            const isCopy = cell.classList.contains('expanded');

            if (isCopy) {
                // If the cell is a copy, remove it
                cell.remove();
                const spanToRemove = currentCopy.querySelector('span');
                spans = spans.filter(span => span !== spanToRemove);
                currentCopy = null;
            } else {
                if (!currentCopy) {
                    // Otherwise, create a copy and add it to the grid
                    const copy = cell.cloneNode(true);
                    copy.classList.add('expanded'); // Mark it as a copy, so it can be removed later
                    copy.id = "" + Math.random(); // Assign a unique ID to the copy
                    const spanInCopy = copy.querySelector('span');
                    spans.push(spanInCopy);

                    const borderText = ''; // Leave the border text blank by default
                    copy.setAttribute('cents-border-text', borderText); // Store the text in an attribute

                    // Append the copy of the cell into the container
                    container.appendChild(copy);
                    currentCopy = copy;
                }
            }
        });
    });

    document.addEventListener('DOMContentLoaded', () => {
        document.querySelectorAll('.line').forEach(line => line.style.visibility = 'hidden');
        resultDiv = document.getElementById('result');

        // Check browser compatibility
        const hasGetUserMedia = isGetUserMediaSupported();
        const hasWebAudio = isWebAudioSupported();
        const hasAudioWorklet = isAudioWorkletSupported();
        const hasScriptProcessor = isScriptProcessorSupported();
        const isSafariBrowser = isSafari();

        // Display appropriate warnings based on browser capabilities
        if (!hasGetUserMedia) {
            resultDiv.style.visibility = 'visible';
            resultDiv.style.display = 'block';
            resultDiv.style.backgroundColor = '#ffcc00';
            resultDiv.innerHTML = 'Your browser does not support microphone access. Please use a modern browser like Chrome, Firefox, or Edge.';
        } else if (!hasWebAudio) {
            resultDiv.style.visibility = 'visible';
            resultDiv.style.display = 'block';
            resultDiv.style.backgroundColor = '#ffcc00';
            resultDiv.innerHTML = 'Your browser does not support audio processing. Please use a modern browser like Chrome, Firefox, or Edge.';
        } else if (!hasAudioWorklet && !hasScriptProcessor) {
            resultDiv.style.visibility = 'visible';
            resultDiv.style.display = 'block';
            resultDiv.style.backgroundColor = '#ffcc00';
            resultDiv.innerHTML = 'Your browser does not support required audio processing features. Please use a modern browser like Chrome, Firefox, or Edge.';
        } else if (isSafariBrowser) {
            resultDiv.style.visibility = 'visible';
            resultDiv.style.display = 'block';
            resultDiv.style.backgroundColor = '#ffcc00';
            resultDiv.innerHTML = 'Safari has limited support for audio processing. The app will use a fallback method which may affect performance.';
        }

        document.getElementById('start').addEventListener('click', async () => {
            document.getElementById('start').disabled = true;
            document.getElementById('stop').disabled = false;

            resultDiv.style.visibility = 'hidden';
            resultDiv.style.display = 'none';

            concertPitch = document.getElementById('supportedConcertPitches').value;
            NoteLookup.concertPitch = concertPitch;

            confidence = document.getElementById('supportedConfidences').value;

            algorithm = document.getElementById('supportedAlgorithms').value;

            // Get harmonica frequency range from hidden fields
            const harmonicaMinFrequency = parseFloat(document.getElementById('harmonicaMinFrequency').value);
            const harmonicaMaxFrequency = parseFloat(document.getElementById('harmonicaMaxFrequency').value);

            console.log("minFrequency: " + harmonicaMinFrequency);
            console.log("maxFrequency: " + harmonicaMaxFrequency);


            // Set frequency range in pitch detectors
            YINPitchDetector.setMinFrequency(harmonicaMinFrequency);
            YINPitchDetector.setMaxFrequency(harmonicaMaxFrequency);
            MPMPitchDetector.setMinFrequency(harmonicaMinFrequency);
            MPMPitchDetector.setMaxFrequency(harmonicaMaxFrequency);
            HybridPitchDetector.setMinFrequency(harmonicaMinFrequency);
            HybridPitchDetector.setMaxFrequency(harmonicaMaxFrequency);


            try {
                // Request microphone access with error handling
                try {
                    mediaStream = await navigator.mediaDevices.getUserMedia({audio: true});
                } catch (micError) {
                    handleError(new Error(`Microphone access denied: ${micError.message}`));
                    return;
                }

                // Initialize AudioContext with fallback
                const AudioContextClass = window.AudioContext || window.webkitAudioContext;
                audioContext = new AudioContextClass();

                // Resume AudioContext if it's suspended (needed for some browsers)
                if (audioContext.state === 'suspended') {
                    await audioContext.resume();
                }

                // Feature-based processing
                if (isAudioWorkletSupported() && !isSafari()) {
                    try {
                        // Modern approach with AudioWorkletNode
                        await audioContext.audioWorklet.addModule('./scripts/PitchProcessor.js');

                        processingNode = new AudioWorkletNode(audioContext, 'pitch-processor', {
                            numberOfInputs: 1,
                            numberOfOutputs: 1,
                            processorOptions: {
                                sampleRate: audioContext.sampleRate,
                                algorithm: algorithm
                            },
                        });

                        processingNode.port.onmessage = (event) => {
                            processAudioResult(event.data);
                        };
                    } catch (workletError) {
                        console.warn("AudioWorklet failed to initialize, falling back to ScriptProcessor:", workletError);
                        // If AudioWorklet fails, fall back to ScriptProcessor
                        if (isScriptProcessorSupported()) {
                            initializeScriptProcessor();
                        } else {
                            throw new Error("Neither AudioWorklet nor ScriptProcessor are available");
                        }
                    }
                } else if (isScriptProcessorSupported()) {
                    // Fallback to the old ScriptProcessorNode
                    initializeScriptProcessor();
                } else {
                    throw new Error("Your browser doesn't support required audio processing features");
                }

                // Helper function to initialize ScriptProcessor
                function initializeScriptProcessor() {
                    processingNode = audioContext.createScriptProcessor(8192, 1, 1);

                    processingNode.onaudioprocess = (e) => {
                        const audioData = e.inputBuffer.getChannelData(0);
                        let result;
                        if(algorithm === 'YIN') {
                            result = YINPitchDetector.detectPitch(audioData, audioContext.sampleRate);
                        }
                        else if(algorithm === 'MPM') {
                            result = MPMPitchDetector.detectPitch(audioData, audioContext.sampleRate);
                        }
                        else if(algorithm === 'HYBRID') {
                            result = HybridPitchDetector.detectPitch(audioData, audioContext.sampleRate);
                        }
                        processAudioResult(result);
                    };
                }

                const source = audioContext.createMediaStreamSource(mediaStream);
                source.connect(processingNode);
                processingNode.connect(audioContext.destination);

            } catch (err) {
                handleError(err);
            }
        });


        /**
         * Processes the audio result by analyzing pitch, determining the note name, calculating cents deviation,
         * and updating the provided results and handling changes accordingly.
         *
         * @param {Object} result - The audio processing result object.
         * @param {number} result.pitch - The detected pitch from the audio analysis.
         * @param {number} result.confidence - The confidence level of the pitch detection.
         * @return {void} The function does not return a value.
         */
        function processAudioResult(result) {
            if (result.pitch) {
                const noteName = NoteLookup.getNoteName(result.pitch);
                if (noteName) {
                    const noteFrequency = NoteLookup.getFrequency(noteName);
                    const cents = NoteUtils.getCents(noteFrequency, result.pitch);
                    const data = {
                        noteName: noteName,
                        cents: cents,
                        confidence: result.confidence,
                    };

                    resultDiv.innerHTML = `noteName: ${noteName}, cents: ${cents}, confidence: ${result.confidence}`;
                    handleChange(data, confidence);
                }
            }
        }

        /**
         * Handles errors related to audio processing and updates the UI accordingly.
         * Provides user-friendly error messages based on the type of error.
         *
         * @param {Error} err - The error object representing the issue encountered.
         * @return {void} This function does not return a value.
         */
        function handleError(err) {
            console.error("Audio processing error:", err);

            let errorMessage = err.message;
            let errorColor = 'red';

            // Provide more user-friendly error messages based on error type
            if (errorMessage.includes('Permission denied') || errorMessage.includes('access denied') || 
                errorMessage.includes('NotAllowedError') || errorMessage.includes('PermissionDeniedError')) {
                errorMessage = "Microphone access was denied. Please allow microphone access and try again.";
            } else if (errorMessage.includes('NotFoundError') || errorMessage.includes('DevicesNotFoundError')) {
                errorMessage = "No microphone was found. Please connect a microphone and try again.";
            } else if (errorMessage.includes('NotReadableError') || errorMessage.includes('TrackStartError')) {
                errorMessage = "Could not access your microphone. It may be in use by another application.";
            } else if (errorMessage.includes('AbortError')) {
                errorMessage = "Microphone access was aborted. Please try again.";
            } else if (errorMessage.includes('SecurityError')) {
                errorMessage = "Microphone access was blocked due to security restrictions. Please use HTTPS or localhost.";
            } else if (errorMessage.includes('support')) {
                // For browser support issues, use yellow instead of red
                errorColor = '#ffcc00';
            }

            // Update UI
            resultDiv.style.visibility = 'visible';
            resultDiv.style.display = 'block';
            resultDiv.style.backgroundColor = errorColor;
            resultDiv.innerHTML = errorMessage;

            // Reset button states
            document.getElementById('start').disabled = false;
            document.getElementById('stop').disabled = true;

            // Clean up any existing audio resources
            if (processingNode) {
                processingNode.disconnect();
                processingNode = null;
            }
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }
            if (audioContext) {
                audioContext.close().catch(e => console.warn("Error closing AudioContext:", e));
                audioContext = null;
            }
        }

        // Stop button handler
        document.getElementById('stop').addEventListener('click', () => {
            if (processingNode) {
                processingNode.disconnect();
            }
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
            }
            if (audioContext) {
                audioContext.close();
            }

            resultDiv.innerHTML = "Streaming stopped.";
            document.getElementById('start').disabled = false;
            document.getElementById('stop').disabled = true;
        });
    });
</script>
</body>
</html>
